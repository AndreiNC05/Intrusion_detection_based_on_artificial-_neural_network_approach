{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPool1D\n",
    "from keras.initializers import random_uniform\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,Dense,LSTM,Dropout,Flatten,BatchNormalization,Conv1D,GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.optimizers import  SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import SimpleRNN\n",
    "#from hyperas.distributions import uniform\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-guyana",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'...') # Use your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into features and labels.\n",
    "\n",
    "labels = dataset['Label']\n",
    "features = dataset.loc[:, dataset.columns != 'Label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Robust Scalar to scale data \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(features)\n",
    "features = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if scaling was done\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder = LabelEncoder()\n",
    "LabelEncoder.fit(labels)\n",
    "labels = LabelEncoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the labels with integers\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if reverse encoding works\n",
    "check = LabelEncoder.inverse_transform(labels)\n",
    "check = pd.Series(check)\n",
    "check.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-prime",
   "metadata": {},
   "source": [
    "### Performing cross validation for neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model():\n",
    "    # Compile model\n",
    "    dnn1= Sequential()\n",
    "    dnn1.add(Dense(128,input_dim=77 ,activation='relu'))\n",
    "    dnn1.add(Dropout(0.1))\n",
    "    dnn1.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    dnn1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return dnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier( build_fn=create_model, epochs= 30, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "# StratifiedKFold is a variation of Kfold that first shuffles the data with a given random state\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results = cross_val_score(model, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-liverpool",
   "metadata": {},
   "source": [
    "# Performing cross validation for deep neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_dnn2():\n",
    "    # Compile model\n",
    "    model= Sequential()\n",
    "    model.add(Dense(128,input_dim=77 ,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "dnn2 = KerasClassifier( build_fn=create_model_dnn2, epochs= 30, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_dnn2 = cross_val_score(dnn2, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_dnn2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-greene",
   "metadata": {},
   "source": [
    "### Performing cross validation for deep neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_dnn3():\n",
    "    # Compile model\n",
    "    model= Sequential()\n",
    "    model.add(Dense(256,input_dim=77 ,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "dnn3 = KerasClassifier( build_fn=create_model_dnn2, epochs= 30, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_dnn3 = cross_val_score(dnn3, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_dnn3.mean())\n",
    "results_dnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-matthew",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(labels)\n",
    "X_train = np.array(features).reshape(features.shape[0], features.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn1():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn1 = Sequential()\n",
    "    cnn1.add(Conv1D(64, 3,input_shape=(77, 1) ))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(MaxPooling1D(pool_size=2))\n",
    "    cnn1.add(Dropout(0.3))\n",
    "\n",
    "    cnn1.add(Flatten())\n",
    "    cnn1.add(Dense(64, input_dim=78, kernel_initializer=hidden_initializer))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(Dense(32))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(Dense(15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn1 = KerasClassifier( build_fn=create_model_cnn1, epochs= 30, batch_size=1024, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_cnn1 = cross_val_score(cnn1, X_train, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn1.mean())\n",
    "results_cnn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-seattle",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn2():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn2 = Sequential()\n",
    "    cnn2.add(Conv1D(64, 3,input_shape=(77, 1) ))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(MaxPooling1D(pool_size=2))\n",
    "    cnn2.add(Dropout(0.3))\n",
    "\n",
    "    cnn2.add(Conv1D(32, 1))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(MaxPooling1D(pool_size=2))\n",
    "    cnn2.add(Dropout(0.3))\n",
    "\n",
    "    cnn2.add(Flatten())\n",
    "    cnn2.add(Dense(64, input_dim=77, kernel_initializer=hidden_initializer))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(Dense(32))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(Dense(15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn2 = KerasClassifier(build_fn=create_model_cnn2, epochs= 30, batch_size=1024, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "Three_kfold = StratifiedKFold(n_splits= 3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 3 folds\n",
    "results_cnn2 = cross_val_score(cnn2, X_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn2.mean())\n",
    "results_cnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-syndication",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn3():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv1D(64, 3,input_shape=(77, 1) ))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.3))\n",
    "\n",
    "    cnn3.add(Conv1D(64, 1))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.4))\n",
    "\n",
    "    cnn3.add(Conv1D(64, 1))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    cnn3.add(Flatten())\n",
    "    cnn3.add(Dense(64, input_dim=77, kernel_initializer=hidden_initializer))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(Dense(32))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(Dense(15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn3 = KerasClassifier( build_fn=create_model_cnn3, epochs= 30, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "Three_kfold = StratifiedKFold(n_splits= 3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 3 folds\n",
    "results_cnn3 = cross_val_score(cnn3, X_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn3.mean())\n",
    "results_cnn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-baseline",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train = np.array(features).reshape(features.shape[0], features.shape[1], 1)\n",
    "ft_labels= to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn1():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn1 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn1.add(SimpleRNN(units = 64,input_shape=(77, 1), activation='relu', return_sequences = True,))\n",
    "    rnn1.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn1.add(Flatten())\n",
    "    rnn1.add(Dense(64, input_dim=77, kernel_initializer=hidden_initializer))\n",
    "    rnn1.add(LeakyReLU(alpha=0.1))\n",
    "    rnn1.add(Dense(32))\n",
    "    rnn1.add(LeakyReLU(alpha=0.1))\n",
    "    rnn1.add(Dense(units = 15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn1 = KerasClassifier( build_fn=create_model_rnn1, epochs= 30, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "Three_kfold = StratifiedKFold(n_splits= 3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 3 folds\n",
    "results_rnn1 = cross_val_score(rnn1, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-mystery",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn2():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn2 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn2.add(SimpleRNN(units = 64,input_shape=(77, 1), activation='relu', return_sequences = True,))\n",
    "    rnn2.add(Dropout(0.1))\n",
    "    \n",
    "    # Adding the second RNN layer and some Dropout regularisation\n",
    "    rnn2.add(SimpleRNN(units = 64, activation='relu', return_sequences = True,))\n",
    "    rnn2.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn2.add(Flatten())\n",
    "    rnn2.add(Dense(64, input_dim=77, kernel_initializer=hidden_initializer))\n",
    "    rnn2.add(LeakyReLU(alpha=0.1))\n",
    "    rnn2.add(Dense(32))\n",
    "    rnn2.add(LeakyReLU(alpha=0.1))\n",
    "    rnn2.add(Dense(units = 15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn2 = KerasClassifier( build_fn=create_model_rnn2, epochs= 30, batch_size=1024, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "Three_kfold = StratifiedKFold(n_splits= 3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 3 folds\n",
    "results_rnn2 = cross_val_score(rnn2, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-columbus",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn3():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn3 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 64,activation='relu', return_sequences = True,  input_shape = (77,1)))\n",
    "    rnn3.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 64,activation='relu', return_sequences = True,  ))\n",
    "    rnn3.add(Dropout(0.1))\n",
    "    \n",
    "    # Adding a third RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 64,activation='relu', return_sequences = True))\n",
    "    rnn3.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn3.add(Flatten())\n",
    "    rnn3.add(Dense(64, input_dim=77, kernel_initializer=hidden_initializer))\n",
    "    rnn3.add(LeakyReLU(alpha=0.1))\n",
    "    rnn3.add(Dense(32))\n",
    "    rnn3.add(LeakyReLU(alpha=0.1))\n",
    "    rnn3.add(Dense(units = 15, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn3 = KerasClassifier( build_fn=create_model_rnn3, epochs= 30, batch_size=4096, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\n",
    "Three_kfold = StratifiedKFold(n_splits= 3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 3 folds\n",
    "results_rnn3 = cross_val_score(rnn3, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
