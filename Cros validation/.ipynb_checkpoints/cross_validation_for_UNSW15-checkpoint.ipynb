{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "piano-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPool1D\n",
    "from keras.initializers import random_uniform\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,Dense,LSTM,Dropout,Flatten,BatchNormalization,Conv1D,GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.optimizers import  SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import SimpleRNN\n",
    "#from hyperas.distributions import uniform\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-pierce",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attempted-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'...') # Use your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virtual-baptist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>111111.107200</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0  0.921987     78        0      5     20      0    1280       0   \n",
       "1  0.921987     78        0      5     20      0    1280       0   \n",
       "2  0.921987     78        0      5     20      0    1280       0   \n",
       "3  0.921987     78        0      5     20      0    1280       0   \n",
       "4  0.000009     97        0      5      2      0     104       0   \n",
       "\n",
       "            rate  sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0      20.607666   254  ...                 1               2             0   \n",
       "1      20.607666   254  ...                 1               2             0   \n",
       "2      20.607666   254  ...                 1               2             0   \n",
       "3      20.607666   254  ...                 1               2             0   \n",
       "4  111111.107200   254  ...                 1               2             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           1                0   \n",
       "1           0                 0           1           1                0   \n",
       "2           0                 0           1           1                0   \n",
       "3           0                 0           1           1                0   \n",
       "4           0                 0           1           1                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0           7      1  \n",
       "1           7      1  \n",
       "2           1      1  \n",
       "3           2      1  \n",
       "4           3      1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vital-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into features and labels.\n",
    "\n",
    "labels = dataset['label']\n",
    "features = dataset.loc[:, dataset.columns != 'label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enhanced-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329346, 44)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "insured-viking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.921987</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.607666</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111111.107200</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0  0.921987   78.0      0.0    5.0   20.0    0.0  1280.0     0.0   \n",
       "1  0.921987   78.0      0.0    5.0   20.0    0.0  1280.0     0.0   \n",
       "2  0.921987   78.0      0.0    5.0   20.0    0.0  1280.0     0.0   \n",
       "3  0.921987   78.0      0.0    5.0   20.0    0.0  1280.0     0.0   \n",
       "4  0.000009   97.0      0.0    5.0    2.0    0.0   104.0     0.0   \n",
       "\n",
       "            rate   sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0      20.607666  254.0  ...               1.0               1.0   \n",
       "1      20.607666  254.0  ...               1.0               1.0   \n",
       "2      20.607666  254.0  ...               1.0               1.0   \n",
       "3      20.607666  254.0  ...               1.0               1.0   \n",
       "4  111111.107200  254.0  ...               1.0               1.0   \n",
       "\n",
       "   ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
       "0             2.0           0.0         0.0               0.0         1.0   \n",
       "1             2.0           0.0         0.0               0.0         1.0   \n",
       "2             2.0           0.0         0.0               0.0         1.0   \n",
       "3             2.0           0.0         0.0               0.0         1.0   \n",
       "4             2.0           0.0         0.0               0.0         1.0   \n",
       "\n",
       "   ct_srv_dst  is_sm_ips_ports  attack_cat  \n",
       "0         1.0              0.0         7.0  \n",
       "1         1.0              0.0         7.0  \n",
       "2         1.0              0.0         1.0  \n",
       "3         1.0              0.0         2.0  \n",
       "4         1.0              0.0         3.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooperative-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scaling the data, we use RobustScaler class from sklearn.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accepted-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(features)\n",
    "\n",
    "features = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifth-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comprehensive-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "\n",
    "LE.fit(labels)\n",
    "labels = LE.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "processed-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels have been replaced with integers.\n",
    "\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hundred-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that encoding reversal works.\n",
    "\n",
    "d = LE.inverse_transform(labels)\n",
    "d = pd.Series(d)\n",
    "d.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-prize",
   "metadata": {},
   "source": [
    "### Performing cross validation for neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model():\n",
    "    # Compile model\n",
    "    dnn1= Sequential()\n",
    "    dnn1.add(Dense(256,input_dim=43 ,activation='relu'))\n",
    "    dnn1.add(Dropout(0.1))\n",
    "    dnn1.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    dnn1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return dnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier( build_fn=create_model, epochs= 30, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "# StratifiedKFold is a variation of Kfold that first shuffles the data with a given random state\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results = cross_val_score(model, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-endorsement",
   "metadata": {},
   "source": [
    "### Performing cross validation for deep neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_dnn2():\n",
    "    # Compile model\n",
    "    model= Sequential()\n",
    "    model.add(Dense(256,input_dim=43 ,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "dnn2 = KerasClassifier( build_fn=create_model_dnn2, epochs= 30, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_dnn2 = cross_val_score(dnn2, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_dnn2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-nerve",
   "metadata": {},
   "source": [
    "### Performing cross validation for deep neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_dnn3():\n",
    "    # Compile model\n",
    "    model= Sequential()\n",
    "    model.add(Dense(256,input_dim=43 ,activation='relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "dnn3 = KerasClassifier( build_fn=create_model_dnn2, epochs= 30, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_dnn3 = cross_val_score(dnn3, features, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_dnn3.mean())\n",
    "results_dnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-trail",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(labels)\n",
    "X_train = np.array(features).reshape(features.shape[0], features.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn1():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn1 = Sequential()\n",
    "    cnn1.add(Conv1D(64, 3,input_shape=(43, 1) ))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(MaxPooling1D(pool_size=2))\n",
    "    cnn1.add(Dropout(0.3))\n",
    "\n",
    "    cnn1.add(Flatten())\n",
    "    cnn1.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(Dense(32))\n",
    "    cnn1.add(LeakyReLU(alpha=0.1))\n",
    "    cnn1.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn1 = KerasClassifier( build_fn=create_model_cnn1, epochs= 30, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_cnn1 = cross_val_score(cnn1, X_train, labels, cv=kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn1.mean())\n",
    "results_cnn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-lemon",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn2():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn2 = Sequential()\n",
    "    cnn2.add(Conv1D(64, 3,input_shape=(43, 1) ))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(MaxPooling1D(pool_size=2))\n",
    "    cnn2.add(Dropout(0.3))\n",
    "\n",
    "    cnn2.add(Conv1D(32, 1))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(MaxPooling1D(pool_size=2))\n",
    "    cnn2.add(Dropout(0.3))\n",
    "\n",
    "    cnn2.add(Flatten())\n",
    "    cnn2.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(Dense(32))\n",
    "    cnn2.add(LeakyReLU(alpha=0.1))\n",
    "    cnn2.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn2 = KerasClassifier(build_fn=create_model_cnn2, epochs= 30, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_cnn2 = cross_val_score(cnn2, X_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn2.mean())\n",
    "results_cnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-sector",
   "metadata": {},
   "source": [
    "### Performing cross validation for convolutional neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_cnn3():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv1D(64, 3,input_shape=(43, 1) ))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.3))\n",
    "\n",
    "    cnn3.add(Conv1D(64, 1))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.3))\n",
    "\n",
    "    cnn3.add(Conv1D(64, 1))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(MaxPooling1D(pool_size=2))\n",
    "    cnn3.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    cnn3.add(Flatten())\n",
    "    cnn3.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(Dense(32))\n",
    "    cnn3.add(LeakyReLU(alpha=0.1))\n",
    "    cnn3.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    cnn3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "cnn3 = KerasClassifier( build_fn=create_model_cnn3, epochs= 30, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_cnn3 = cross_val_score(cnn3, X_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_cnn3.mean())\n",
    "results_cnn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-argument",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train = np.array(features).reshape(features.shape[0], features.shape[1], 1)\n",
    "ft_labels= to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn1():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn1 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn1.add(SimpleRNN(units = 64,input_shape=(43, 1), activation='relu', return_sequences = True,))\n",
    "    rnn1.add(Dropout(0.3))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn1.add(Flatten())\n",
    "    rnn1.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    rnn1.add(LeakyReLU(alpha=0.1))\n",
    "    rnn1.add(Dense(32))\n",
    "    rnn1.add(LeakyReLU(alpha=0.1))\n",
    "    rnn1.add(Dense(units = 2, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn1 = KerasClassifier( build_fn=create_model_rnn1, epochs= 30, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_rnn1 = cross_val_score(rnn1, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-singapore",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn2():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn2 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn2.add(SimpleRNN(units = 64,input_shape=(43, 1), activation='relu', return_sequences = True,))\n",
    "    rnn2.add(Dropout(0.1))\n",
    "    \n",
    "    # Adding the second RNN layer and some Dropout regularisation\n",
    "    rnn2.add(SimpleRNN(units = 64, activation='relu', return_sequences = True,))\n",
    "    rnn2.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn2.add(Flatten())\n",
    "    rnn2.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    rnn2.add(LeakyReLU(alpha=0.1))\n",
    "    rnn2.add(Dense(32))\n",
    "    rnn2.add(LeakyReLU(alpha=0.1))\n",
    "    rnn2.add(Dense(units = 2, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn2 = KerasClassifier( build_fn=create_model_rnn2, epochs= 30, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_rnn2 = cross_val_score(rnn2, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-hunger",
   "metadata": {},
   "source": [
    "### Performing cross validation for recurrent neural network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create the model needed for KerasClassifier\n",
    "def create_model_rnn3():\n",
    "    # create model\n",
    "    SEED = 1040941203\n",
    "    hidden_initializer = random_uniform(seed=SEED)\n",
    "\n",
    "    # Initialising the RNN\n",
    "    rnn3 = Sequential()\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 32,activation='relu', return_sequences = True,  input_shape = (43,1)))\n",
    "    rnn3.add(Dropout(0.3))\n",
    "\n",
    "    # Adding the first RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 32,activation='relu', return_sequences = True,  ))\n",
    "    rnn3.add(Dropout(0.3))\n",
    "    \n",
    "    # Adding a third RNN layer and some Dropout regularisation\n",
    "    rnn3.add(SimpleRNN(units = 32,activation='relu', return_sequences = True))\n",
    "    rnn3.add(Dropout(0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    rnn3.add(Flatten())\n",
    "    rnn3.add(Dense(64, input_dim=43, kernel_initializer=hidden_initializer))\n",
    "    rnn3.add(LeakyReLU(alpha=0.1))\n",
    "    rnn3.add(Dense(32))\n",
    "    rnn3.add(LeakyReLU(alpha=0.1))\n",
    "    rnn3.add(Dense(units = 2, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    rnn3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return rnn3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "rnn3 = KerasClassifier( build_fn=create_model_rnn3, epochs= 30, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the mean accuracy value for the 5 folds\n",
    "results_rnn3 = cross_val_score(rnn3, ft_train, labels, cv=Three_kfold,scoring='accuracy', error_score=\"raise\")\n",
    "print(results_rnn3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
